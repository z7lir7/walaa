Model,Method,Accuracy,Classification Report
SVM,TF-IDF,0.9775280898876404,"{'business': {'precision': 0.9801980198019802, 'recall': 0.9705882352941176, 'f1-score': 0.9753694581280788, 'support': 102.0}, 'entertainment': {'precision': 0.9625, 'recall': 1.0, 'f1-score': 0.9808917197452229, 'support': 77.0}, 'politics': {'precision': 0.9642857142857143, 'recall': 0.9642857142857143, 'f1-score': 0.9642857142857143, 'support': 84.0}, 'sport': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 102.0}, 'tech': {'precision': 0.9743589743589743, 'recall': 0.95, 'f1-score': 0.9620253164556962, 'support': 80.0}, 'accuracy': 0.9775280898876404, 'macro avg': {'precision': 0.9762685416893337, 'recall': 0.9769747899159664, 'f1-score': 0.9765144417229425, 'support': 445.0}, 'weighted avg': {'precision': 0.97762115947982, 'recall': 0.9775280898876404, 'f1-score': 0.9774794886874201, 'support': 445.0}}"
Naive Bayes,TF-IDF,0.9820224719101124,"{'business': {'precision': 0.99, 'recall': 0.9705882352941176, 'f1-score': 0.9801980198019802, 'support': 102.0}, 'entertainment': {'precision': 0.9746835443037974, 'recall': 1.0, 'f1-score': 0.9871794871794872, 'support': 77.0}, 'politics': {'precision': 0.975609756097561, 'recall': 0.9523809523809523, 'f1-score': 0.963855421686747, 'support': 84.0}, 'sport': {'precision': 0.9902912621359223, 'recall': 1.0, 'f1-score': 0.9951219512195122, 'support': 102.0}, 'tech': {'precision': 0.9753086419753086, 'recall': 0.9875, 'f1-score': 0.9813664596273292, 'support': 80.0}, 'accuracy': 0.9820224719101124, 'macro avg': {'precision': 0.9811786409025179, 'recall': 0.982093837535014, 'f1-score': 0.9815442679030111, 'support': 445.0}, 'weighted avg': {'precision': 0.9820589944257894, 'recall': 0.9820224719101124, 'f1-score': 0.9819519769637883, 'support': 445.0}}"
Random Forest,TF-IDF,0.9752808988764045,"{'business': {'precision': 0.97, 'recall': 0.9509803921568627, 'f1-score': 0.9603960396039604, 'support': 102.0}, 'entertainment': {'precision': 0.9746835443037974, 'recall': 1.0, 'f1-score': 0.9871794871794872, 'support': 77.0}, 'politics': {'precision': 0.963855421686747, 'recall': 0.9523809523809523, 'f1-score': 0.9580838323353293, 'support': 84.0}, 'sport': {'precision': 0.9807692307692307, 'recall': 1.0, 'f1-score': 0.9902912621359223, 'support': 102.0}, 'tech': {'precision': 0.9873417721518988, 'recall': 0.975, 'f1-score': 0.9811320754716981, 'support': 80.0}, 'accuracy': 0.9752808988764045, 'macro avg': {'precision': 0.9753299937823348, 'recall': 0.975672268907563, 'f1-score': 0.9754165393452794, 'support': 445.0}, 'weighted avg': {'precision': 0.9752366104352643, 'recall': 0.9752808988764045, 'f1-score': 0.9751742320094202, 'support': 445.0}}"
SVM,Bag of Words,0.9617977528089887,"{'business': {'precision': 0.9895833333333334, 'recall': 0.9313725490196079, 'f1-score': 0.9595959595959596, 'support': 102.0}, 'entertainment': {'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1-score': 0.967741935483871, 'support': 77.0}, 'politics': {'precision': 0.9642857142857143, 'recall': 0.9642857142857143, 'f1-score': 0.9642857142857143, 'support': 84.0}, 'sport': {'precision': 1.0, 'recall': 0.9705882352941176, 'f1-score': 0.9850746268656716, 'support': 102.0}, 'tech': {'precision': 0.8863636363636364, 'recall': 0.975, 'f1-score': 0.9285714285714286, 'support': 80.0}, 'accuracy': 0.9617977528089887, 'macro avg': {'precision': 0.9603542291042292, 'recall': 0.9630544945250827, 'f1-score': 0.961053932960529, 'support': 445.0}, 'weighted avg': {'precision': 0.9637866347136009, 'recall': 0.9617977528089887, 'f1-score': 0.9621533553641769, 'support': 445.0}}"
Naive Bayes,Bag of Words,0.9820224719101124,"{'business': {'precision': 0.99, 'recall': 0.9705882352941176, 'f1-score': 0.9801980198019802, 'support': 102.0}, 'entertainment': {'precision': 0.9871794871794872, 'recall': 1.0, 'f1-score': 0.9935483870967742, 'support': 77.0}, 'politics': {'precision': 0.9759036144578314, 'recall': 0.9642857142857143, 'f1-score': 0.9700598802395209, 'support': 84.0}, 'sport': {'precision': 0.9807692307692307, 'recall': 1.0, 'f1-score': 0.9902912621359223, 'support': 102.0}, 'tech': {'precision': 0.975, 'recall': 0.975, 'f1-score': 0.975, 'support': 80.0}, 'accuracy': 0.9820224719101124, 'macro avg': {'precision': 0.9817704664813098, 'recall': 0.9819747899159663, 'f1-score': 0.9818195098548396, 'support': 445.0}, 'weighted avg': {'precision': 0.9820386194735727, 'recall': 0.9820224719101124, 'f1-score': 0.9819733988859267, 'support': 445.0}}"
Random Forest,Bag of Words,0.9730337078651685,"{'business': {'precision': 0.979381443298969, 'recall': 0.9313725490196079, 'f1-score': 0.9547738693467337, 'support': 102.0}, 'entertainment': {'precision': 0.9746835443037974, 'recall': 1.0, 'f1-score': 0.9871794871794872, 'support': 77.0}, 'politics': {'precision': 0.963855421686747, 'recall': 0.9523809523809523, 'f1-score': 0.9580838323353293, 'support': 84.0}, 'sport': {'precision': 0.9805825242718447, 'recall': 0.9901960784313726, 'f1-score': 0.9853658536585366, 'support': 102.0}, 'tech': {'precision': 0.963855421686747, 'recall': 1.0, 'f1-score': 0.9815950920245399, 'support': 80.0}, 'accuracy': 0.9730337078651685, 'macro avg': {'precision': 0.9724716710496211, 'recall': 0.9747899159663866, 'f1-score': 0.9733996269089253, 'support': 445.0}, 'weighted avg': {'precision': 0.9731219028320043, 'recall': 0.9730337078651685, 'f1-score': 0.9728398236797504, 'support': 445.0}}"
